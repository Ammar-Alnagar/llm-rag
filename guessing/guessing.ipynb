{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "class Player:\n",
    "    def __init__(self, model):\n",
    "        self.observations = []\n",
    "        self.model = model\n",
    "\n",
    "    def ask(self, questions_left):\n",
    "        template = \"\"\"\n",
    "        You are a player in a game where you need to ask Yes/No questions about \n",
    "        a thing and guess what it is.\n",
    "\n",
    "        Here is what you already know about this thing:\n",
    "\n",
    "        {observations}\n",
    "\n",
    "        You only have {questions_left} questions left to ask. You want to guess\n",
    "        the thing in as few questions as possible. If there's only 1 question left, \n",
    "        you must make a guess or you'll lose the game. Be aggresive and try to\n",
    "        guess the thing as soon as possible.\n",
    "\n",
    "        You can also ask a binary question that will help you guess the thing.\n",
    "        The question must be answered with a Yes/No. No other questions are allowed.\n",
    "         \n",
    "        Be as concise as possible when asking a question. Do not anounce that you\n",
    "        will ask the question. Do not say \"Let's get started\", or introduce your \n",
    "        question. Just write the question.\n",
    "\n",
    "        If you already know what the thing is, write your guess by saying\n",
    "        \"My guess is <thing>.\" For example, if you think the thing is an apple,\n",
    "        write \"My guess is apple\".\n",
    "\n",
    "        Examples of good questions:\n",
    "\n",
    "        - Is it a fruit?\n",
    "        - Is it bigger than a car?\n",
    "        - Is the thing alive?\n",
    "\n",
    "        Examples of bad questions:\n",
    "\n",
    "        - Can I ask a question?\n",
    "        - Can you tell me more about the thing?\n",
    "        - What is the thing?\n",
    "        - How does the thing look like?\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        chain = prompt | self.model | StrOutputParser()\n",
    "        return chain.invoke(\n",
    "            {\n",
    "                \"observations\": \"\\n\".join(self.observations),\n",
    "                \"questions_left\": questions_left,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def add_observation(self, question, answer):\n",
    "        self.observations.append(f\"Question: {question}. Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is it a living thing?'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "player1 = Player(model=Ollama(model=\"llama3\"))\n",
    "question = player1.ask(20)\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Host:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def answer(self, concept, question):\n",
    "        template = \"\"\"\n",
    "        You are the host of a game where a player asks questions about\n",
    "        a thing to guess what it is.\n",
    "\n",
    "        The thing is: {concept}.\n",
    "\n",
    "        The player has asked you the following question: {question}.\n",
    "\n",
    "        If the player guessed the thing, answer with the word \"GUESSED\".\n",
    "        Do not write anything else. Do not be pedantic and be lenient\n",
    "        in your evaluation. For example, If the player guessed \"PC\" or \n",
    "        \"laptop\" and the concept is \"Computer\", you should answer \"GUESSED\".\n",
    "\n",
    "        If the player didn't guessed the thing, answer its question with a \n",
    "        simple Yes or No. Do not say anything else. Do not use any punctuation.\n",
    "\n",
    "        For example, if the player asks \"Is the thing a red apple?\", an \n",
    "        the thing is an apple, you should answer \"GUESSED\".\n",
    "\n",
    "        If the player asks \"Is the thing a fruit?\", and the concept is \n",
    "        an apple, you should answer \"Yes\".\n",
    "       \n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        chain = prompt | self.model | StrOutputParser()\n",
    "        return chain.invoke({\"concept\": concept, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "host = Host(model=Ollama(model=\"llama3\"))\n",
    "answer = host.answer(\"cat\", question)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, host_model=\"gpt-3.5-turbo\", player_model=\"llama3\", rounds=20):\n",
    "        self.host_model = host_model\n",
    "        self.player_model = player_model\n",
    "        self.rounds = 20\n",
    "\n",
    "    def start(self, concepts):\n",
    "        score = 0\n",
    "        for concept in concepts:\n",
    "            print(f\"Concept: {concept}\")\n",
    "            score += self._play(concept)\n",
    "\n",
    "        print(\n",
    "            f\"Score: {score} out of {len(concepts)}. Accuracy: {(score / len(concepts)):.2f}\"\n",
    "        )\n",
    "\n",
    "        return score\n",
    "\n",
    "    def _play(self, concept):\n",
    "        host = Host(model=self._create_model(self.host_model))\n",
    "        player = Player(model=self._create_model(self.player_model))\n",
    "\n",
    "        for r in range(self.rounds):\n",
    "            question = player.ask(self.rounds - r)\n",
    "            answer = host.answer(concept, question)\n",
    "\n",
    "            print(f\"Question {r + 1}: {question}. Answer: {answer}\")\n",
    "\n",
    "            player.add_observation(question, answer)\n",
    "\n",
    "            if \"guessed\" in answer.lower():\n",
    "                print(f\"Player guessed the concept: {concept}\")\n",
    "                return True\n",
    "\n",
    "        print(\"The player did not guess the concept.\")\n",
    "        return False\n",
    "\n",
    "    def _create_model(self, model):\n",
    "        if \"gpt\" in model:\n",
    "            return ChatOpenAI(model=model)\n",
    "\n",
    "        return Ollama(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = [\n",
    "    \"cat\",\n",
    "    \"computer\",\n",
    "    \"house\",\n",
    "    \"car\",\n",
    "    \"tree\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: cat\n",
      "Question 1: Is it man-made?. Answer: No\n",
      "Question 2: Is the thing alive?. Answer: Yes\n",
      "Question 3: Is it a plant?. Answer: No\n",
      "Question 4: Is it an animal?. Answer: Yes\n",
      "Question 5: Does it have fur?. Answer: Yes\n",
      "Question 6: Does it have four legs?. Answer: Yes\n",
      "Question 7: Is it a domesticated animal?. Answer: Yes\n",
      "Question 8: Does it bark?. Answer: No\n",
      "Question 9: Does it meow?. Answer: Yes\n",
      "Question 10: My guess is cat.. Answer: GUESSED\n",
      "Player guessed the concept: cat\n",
      "Concept: computer\n",
      "Question 1: Is it a living thing?. Answer: No\n",
      "Question 2: Is it man-made?. Answer: Yes\n",
      "Question 3: Is it used primarily indoors?. Answer: Yes\n",
      "Question 4: Is it electronic?. Answer: Yes\n",
      "Question 5: Is it used for communication?. Answer: Yes\n",
      "Question 6: Is it portable?. Answer: Yes\n",
      "Question 7: Does it primarily fit in the hand?. Answer: No\n",
      "Question 8: Is it used primarily for accessing the internet?. Answer: Yes\n",
      "Question 9: Is it a laptop?. Answer: No\n",
      "Question 10: Is it a tablet?. Answer: No\n",
      "Question 11: Is it a smartphone?. Answer: No\n",
      "Question 12: Is it a smart display?. Answer: Yes\n",
      "Question 13: Is the brand Google?. Answer: No\n",
      "Question 14: Is the brand Amazon?. Answer: No\n",
      "Question 15: Is the brand Apple?. Answer: No\n",
      "Question 16: Is the brand Samsung?. Answer: No\n",
      "Question 17: Is the brand Lenovo?. Answer: No\n",
      "Question 18: Is the brand Microsoft?. Answer: No\n",
      "Question 19: Is the brand Sony?. Answer: No\n",
      "Question 20: Is the brand Facebook?. Answer: No\n",
      "The player did not guess the concept.\n",
      "Concept: house\n",
      "Question 1: Is it a living organism?. Answer: No\n",
      "Question 2: Is it man-made?. Answer: Yes\n",
      "Question 3: Is it used primarily indoors?. Answer: Yes\n",
      "Question 4: Is it an electronic device?. Answer: No\n",
      "Question 5: Is it furniture?. Answer: No\n",
      "Question 6: Is it used for decoration?. Answer: No\n",
      "Question 7: Is it typically found in an office?. Answer: No\n",
      "Question 8: Is it made of paper?. Answer: No\n",
      "Question 9: Is it used in cooking or food preparation?. Answer: No\n",
      "Question 10: Is it used for cleaning?. Answer: No\n",
      "Question 11: Is it used for personal care or hygiene?. Answer: No\n",
      "Question 12: Is it used in games or recreation?. Answer: No\n",
      "Question 13: Is it made of metal?. Answer: No\n",
      "Question 14: Is it made of plastic?. Answer: No\n",
      "Question 15: Is it made of glass?. Answer: No\n",
      "Question 16: Is it made of wood?. Answer: Yes\n",
      "Question 17: Is it used for storage?. Answer: Yes\n",
      "Question 18: Is it typically found in a living room?. Answer: Yes\n",
      "Question 19: Is it used to store books?. Answer: No\n",
      "Question 20: Is it used to store items other than books?. Answer: Yes\n",
      "The player did not guess the concept.\n",
      "Concept: car\n",
      "Question 1: Is it a living thing?. Answer: No\n",
      "Question 2: Is it man-made?. Answer: Yes\n",
      "Question 3: Is it used in everyday life?. Answer: Yes\n",
      "Question 4: Is it electronic?. Answer: No\n",
      "Question 5: Is it made of metal?. Answer: Yes\n",
      "Question 6: Is it used in the kitchen?. Answer: No\n",
      "Question 7: Is it used primarily outdoors?. Answer: Yes\n",
      "Question 8: Is it used for transportation?. Answer: Yes\n",
      "Question 9: Does it have two wheels?. Answer: Yes\n",
      "Question 10: Is it powered by a motor?. Answer: Yes\n",
      "Question 11: Is it a motorcycle?. Answer: No\n",
      "Question 12: Is it a moped?. Answer: No\n",
      "Question 13: Is it a motorized scooter?. Answer: No\n",
      "Question 14: Is it an electric bicycle?. Answer: No\n",
      "Question 15: Is it a gas-powered bicycle?. Answer: No\n",
      "Question 16: Is it used primarily for recreation?. Answer: No\n",
      "Question 17: Is it a motorized kick scooter?. Answer: No\n",
      "Question 18: Is it primarily used for commuting?. Answer: Yes\n",
      "Question 19: Is it a Segway?. Answer: No\n",
      "Question 20: My guess is electric kick scooter.. Answer: No\n",
      "The player did not guess the concept.\n",
      "Concept: tree\n",
      "Question 1: Is it a living organism?. Answer: Yes\n",
      "Question 2: Is it an animal?. Answer: No\n",
      "Question 3: Is it a plant?. Answer: Yes\n",
      "Question 4: Is it typically found outdoors?. Answer: Yes\n",
      "Question 5: Does it produce flowers?. Answer: No\n",
      "Question 6: Is it used for medicinal purposes?. Answer: No\n",
      "Question 7: Does it have needles instead of leaves?. Answer: No\n",
      "Question 8: Does it grow on trees?. Answer: No\n",
      "Question 9: Is it a type of grass?. Answer: No\n",
      "Question 10: Is it a type of moss?. Answer: No\n",
      "Question 11: Is it a type of fern?. Answer: No\n",
      "Question 12: Is it a type of algae?. Answer: No\n",
      "Question 13: Is it a type of herb?. Answer: No\n",
      "Question 14: Is it a vine?. Answer: No\n",
      "Question 15: Does it have a woody stem?. Answer: Yes\n",
      "Question 16: Is it commonly used as timber or for furniture?. Answer: Yes\n",
      "Question 17: Is it commonly used to make paper?. Answer: Yes\n",
      "Question 18: Is it commonly used in construction?. Answer: No\n",
      "Question 19: Is it a type of tree?. Answer: Yes\n",
      "Question 20: Is it commonly used to make books?. Answer: No\n",
      "The player did not guess the concept.\n",
      "Score: 1 out of 5. Accuracy: 0.20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = Game(host_model=\"llama3\", player_model=\"llama3\")\n",
    "game.start(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
